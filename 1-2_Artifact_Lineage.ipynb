{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1.2: Artifact Lineage\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zenml-io/zenbytes/blob/main/1-2_Artifact_Lineage.ipynb)\n",
    "\n",
    "***Key Concepts:*** *Artifacts, Artifact Stores, Metadata, Versioning, Caching*\n",
    "\n",
    "In this lesson we will learn about one of the coolest features of ML pipelines: automated artifact versioning and tracking. This will give us tremendous insights into how exactly each of our models was created. Furthermore, it enables artifact caching, allowing us to switch out parts of our ML pipelines without having to rerun any previous steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires you to have the ZenML [Dash](https://dash.plotly.com/introduction) integration installed. Install it with the following command if you have not done so before, which will also restart the kernel of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install zenml\n",
    "!zenml integration install sklearn dash -y\n",
    "%pip install pyparsing==2.4.2  # required for Colab\n",
    "\n",
    "import IPython\n",
    "\n",
    "# automatically restart kernel\n",
    "IPython.Application.instance().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colab Note:** On Colab, you need an [ngrok account](https://dashboard.ngrok.com/signup) to view some of the visualizations later. Please set up an account, then set your user token below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGROK_TOKEN = \"\"  # TODO: set your ngrok token if you are working on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB ONLY setup\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "\n",
    "    # clone zenbytes repo to get source code of previous lessons\n",
    "    !git clone https://github.com/zenml-io/zenbytes.git  # noqa\n",
    "    !mv zenbytes/steps .\n",
    "    !mv zenbytes/pipelines .\n",
    "\n",
    "    # install ngrok and expose port 8080\n",
    "    !pip install pyngrok\n",
    "    !ngrok authtoken {NGROK_TOKEN}\n",
    "\n",
    "except ModuleNotFoundError as err:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into any versioning and caching, let's clarify what exactly **[Artifacts](https://docs.zenml.io/mlops-stacks/artifact-stores)** are. To illustrate, let us first rebuild our digits pipeline from the previous chapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "from steps.evaluator import evaluator\n",
    "from steps.importer import importer\n",
    "from steps.sklearn_trainer import svc_trainer\n",
    "\n",
    "\n",
    "@pipeline\n",
    "def digits_pipeline(importer, trainer, evaluator):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artifacts of this pipeline are simply the local variables we defined: `X_train`, `X_test`, `y_train`, `y_test`, and `model`. These make up the data that flows in and out of our steps. Artifacts are at the core of our pipelines, and the pipeline definition above just defines which artifact is the input or output of what step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Visualization with Dash\n",
    "\n",
    "To visualize how the steps connect the different artifacts, we can view our pipeline with ZenML's [Dash](https://dash.plotly.com/introduction) integration. \n",
    "\n",
    "Run the following code, then open http://127.0.0.1:8050 in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_svc_pipeline = digits_pipeline(\n",
    "    importer=importer(), trainer=svc_trainer(), evaluator=evaluator()\n",
    ")\n",
    "digits_svc_pipeline.run(unlisted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline_visualizer():\n",
    "    if IN_COLAB:\n",
    "        from pyngrok import ngrok\n",
    "\n",
    "        public_url = ngrok.connect(8050)\n",
    "        print(f\"\\x1b[31mIn Colab, use this URL instead: {public_url}!\\x1b[0m\")\n",
    "\n",
    "    from zenml.integrations.dash.visualizers.pipeline_run_lineage_visualizer import (\n",
    "        PipelineRunLineageVisualizer,\n",
    "    )\n",
    "    from zenml.post_execution import get_unlisted_runs\n",
    "\n",
    "    latest_run = get_unlisted_runs()[-1]\n",
    "    PipelineRunLineageVisualizer().visualize(latest_run)\n",
    "\n",
    "\n",
    "start_pipeline_visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you're running on Colab, you will not be able to access the regular dash link. Instead, use the `ngrok.io` link printed above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see an interactive visualization in your browser, as shown below. The squares represent your artifacts and the circles your pipeline steps. Also, note that the different nodes are color-coded, so if your pipeline ever fails or runs for too long, you can find the responsible step at a glance!\n",
    "\n",
    "![Dash Visualization](_assets/1-2/dash_initial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact Caching\n",
    "As mentioned in the beginning, tracking which exact artifact went into what steps allows us to cache and reuse artifacts. Let's see this in action: First, stop the execution of the last notebook cell if it is still running. Then, execute the next cell to rerun our pipeline and visualize it with dash again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_svc_pipeline.run(unlisted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pipeline_visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a visualization as shown below. Note that the color of all nodes in the graph has changed to green now. This means they were still cached from our previous run.\n",
    "\n",
    "![Dash Visualization Cached](_assets/1-2/dash_cached.png)\n",
    "\n",
    "Let's now replace the SVC model in our ML pipeline with a decision tree and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from zenml.steps import step\n",
    "\n",
    "\n",
    "@step()\n",
    "def tree_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train a sklearn decision tree classifier.\"\"\"\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# redefine and rerun our pipeline, this time with tree_trainer()\n",
    "digits_tree_pipeline = digits_pipeline(\n",
    "    importer=importer(), trainer=tree_trainer(), evaluator=evaluator()\n",
    ")\n",
    "digits_tree_pipeline.run(unlisted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pipeline_visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization should now look as shown below. Since we changed the trainer, the corresponding node and all subsequent nodes are now blue again, meaning they were rerun and the artifacts were freshly created. However, note how the input data artifacts are still green. They did not have to be recreated. In an actual production setting, this might save us a tremendous amount of time and resources as those data artifacts might have resulted from some complex, expensive preprocessing job.\n",
    "\n",
    "![Dash Visualization Partly Cached](_assets/1-2/dash_partly_cached.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact Storage\n",
    "\n",
    "You might now wonder how our ML pipelines can keep track of which artifacts changed and which did not. This requires several additional MLOps components that you would typically have to set up and configure yourself. Luckily, ZenML automatically set this up for us.\n",
    "\n",
    "Under the hood, all the artifacts in our ML pipeline are automatically stored in an [Artifact Store](https://docs.zenml.io/mlops-stacks/artifact-stores). By default, this is simply a place in your local file system, but we could also configure ZenML to store this data in a cloud bucket like [Amazon S3](https://aws.amazon.com/s3/) or any other place instead. We will see this in more detail when we migrate our MLOps stack to the cloud in a later chapter.\n",
    "\n",
    "You can run the following command to find out where exactly your artifacts are currently stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml artifact-store describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZenML MLOps Stacks\n",
    "\n",
    "Artifact stores, together with orchestrators, are the backbone of any ZenML MLOps stack. You can see a list of all components in your current MLOps stack using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrators\n",
    "\n",
    "The [Orchestrator](https://docs.zenml.io/mlops-stacks/orchestrators) is the component that defines how and where each pipeline step is executed when calling `pipeline.run()`. This component is not of much interest to us right now, but we will learn more about it in later chapters, e.g., to run our pipelines on a [Kubernetes](https://kubernetes.io/) clusters with a [Kubeflow](https://www.kubeflow.org/) orchestrator.\n",
    "\n",
    "![Local MLOps Stack](_assets/1-2/localstack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add several more components to our MLOps stack throughout the subsequent chapters, including model deployment tools, experiment trackers, data and model monitoring tools, and more. Let's start with experiment tracking in the [next lesson](2-1_Experiment_Tracking.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec45946565c50b1d690aa5a9e3c974f5b62b9cc8d8934e441e52186140f79402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
